{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in links: https://download.pytorch.org/whl/torch_stable.html\n",
      "Collecting torch==1.8.1+cpu\n",
      "  Downloading https://download.pytorch.org/whl/cpu/torch-1.8.1%2Bcpu-cp37-cp37m-win_amd64.whl (190.4MB)\n",
      "Collecting torchvision==0.9.1+cpu\n",
      "  Downloading https://download.pytorch.org/whl/cpu/torchvision-0.9.1%2Bcpu-cp37-cp37m-win_amd64.whl (845kB)\n",
      "Collecting torchaudio===0.8.1\n",
      "  Downloading https://files.pythonhosted.org/packages/3a/59/f6ffd8f8c4d94326ff4584bf83783a65fcdc8e44c8109cd57d1ed6d38421/torchaudio-0.8.1-cp37-none-win_amd64.whl (109kB)\n",
      "Requirement already satisfied: numpy in d:\\python\\lib\\site-packages (from torch==1.8.1+cpu) (1.19.5)\n",
      "Requirement already satisfied: typing-extensions in d:\\python\\lib\\site-packages (from torch==1.8.1+cpu) (3.7.4.3)\n",
      "Requirement already satisfied: pillow>=4.1.1 in d:\\python\\lib\\site-packages (from torchvision==0.9.1+cpu) (6.2.0)\n",
      "Installing collected packages: torch, torchvision, torchaudio\n",
      "Successfully installed torch-1.8.1+cpu torchaudio-0.8.1 torchvision-0.9.1+cpu\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install torch==1.8.1+cpu torchvision==0.9.1+cpu torchaudio===0.8.1 -f https://download.pytorch.org/whl/torch_stable.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as t\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,)),])\n",
    "\n",
    "mnist_trainset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "train_loader = t.utils.data.DataLoader(mnist_trainset, batch_size=10, shuffle=True)\n",
    "\n",
    "mnist_testset = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
    "test_loader = t.utils.data.DataLoader(mnist_testset, batch_size=10, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.linear1 = nn.Linear(28*28, 100)\n",
    "        self.linear2 = nn.Linear(100, 50)\n",
    "        self.final = nn.Linear(50, 10)\n",
    "        self.relu = nn.ReLU()\n",
    "    def forward(self, img):\n",
    "        x = img.view(-1, 28*28)\n",
    "        x = self.relu(self.linear1(x))\n",
    "        x = self.relu(self.linear2(x))\n",
    "        x = self.final(x)\n",
    "        return x\n",
    "net = Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_el = nn.CrossEntropyLoss()\n",
    "optimizer = t.optim.Adam(net.parameters(), lr=0.001) #e-1\n",
    "epoch = 10\n",
    "\n",
    "for epoch in range(epoch):\n",
    "    net.train()\n",
    "\n",
    "    for data in train_loader:\n",
    "        x, y = data\n",
    "        optimizer.zero_grad()\n",
    "        output = net(x.view(-1, 28*28))\n",
    "        loss = cross_el(output, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.969\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "with t.no_grad():\n",
    "    for data in test_loader:\n",
    "        x, y = data\n",
    "        output = net(x.view(-1, 784))\n",
    "        for idx, i in enumerate(output):\n",
    "            if t.argmax(i) == y[idx]:\n",
    "                correct +=1\n",
    "            total +=1\n",
    "print(f'accuracy: {round(correct/total, 3)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(9)\n"
     ]
    }
   ],
   "source": [
    "plt.imshow(x[3].view(28, 28))\n",
    "plt.show()\n",
    "print(t.argmax(net(x[3].view(-1, 784))[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
